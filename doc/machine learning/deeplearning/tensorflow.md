# 1. Tensorflow概述

## 1.1 主要特性

- 运算性能强劲

线性代数编译器XLA帮助tensorflow在CPU、GPU、TPU、嵌入式设备等平台上更加快速地运行机器学习模型的训练与推理任务

- 框架设计通用

不仅用于机器学习与深度神经网络方面的研究，也可用于其它计算领域，既提供高层封装API，能帮用户快速实现算法模型；又提供底层原生API，可以实现更灵活且高效的分布式并行模式

- 支持生产环境部署
-   语言接口丰富

Tensorflow核心层由C++实现，应用层使用SWIG等技术封装，提供了多语言API的支持，官方支持语言有：Python、C、C++、Java、Go。除此之外Tensorflow的社区也提供了非官方的应用层，如Node.js

- 端云协同计算

Tensorflow同时支持在云侧（服务端）和端侧（移动设备等终端）运行，有效结合了云侧和端侧的优势。在云侧方面，Tensorflow提供多种并行模式和编辑方法，经可能提升算法模型的运行性能；在端侧方面，Tensorflow提供轻量部署和八比特压缩等技术，尽可能提升计算和存储资源利用效率。

## 1.2  基本架构

​		Tensorflow的设计采用库模式，在库模式下，平台软件以静态或者动态的开发库形式存在，应用层开发者需要编写程序调用这些苦提供的函数，实现计算逻辑。出于灵活通用、端云结合及高性能等设计目标的考虑，库模式的平台层软件便于与各种既有的框架协同工作，不对软件的运行时组件添加新的约束，应用范围也不受制约。除依赖最基本的编程语言库与操作系统调用外，同其它环境因数解耦，可移植性强。在单机和终端的情况下，由于没有守护进程和调度框架的开销，计算效率得到提高。

​       构成Tensorflow的主题是其运行时核心库，这个核心库就是pip指令安装时，部署到site-packages或者类似目录的动态链接库文件。生成这类库的C++源代码大致分为三个层次：分布运行时，公共运行时和算子核函数。其中，公共运行时实现了数据流图计算的基本逻辑，分布运行时在此基础上实现了跨进程协同计算逻辑，算子核函数则包括图上具体操作节点的算法实现代码

# 2. Tensorflow基本概念

Tensorflow与Theano、Caffe一样基于声明式编程的数据流图作为编程规范，基于声明式编程的数据流图的好处有代码可读性强、支持引用透明、提供预编译优化能力等，这些都有助于用户定义数学函数或算法模型。

**声明式编程**：结构化、抽象化，用户不必纠结每个步骤的具体实现，而是通过下定义的方式描述期望达到的状态。程序是一个数学模型。擅长基于数理逻辑的应用领域。

**命令式编程**：过程化、具体化，用户告诉机器怎么做，机器按照用户的指示一步步执行命令，并转换到最终的状态。程序是一个有穷自动机，擅长复杂业务逻辑的应用领域。

提供预编译优化能力：其运行时环境不像解释型命令式语法那样即刻执行代码，二十蕾仕于编译型命令式语言的语法树生成过程，需要事先编译得到完整的数据流图，然后根据用户选择的子图，输入数据进行计算



## 数据流图

Tensorflow将数据流图明确地定义为：以节点和有向边描述数学运算的有向无环图。数据流图中的节点通常代表各类操作（Operation）, 具体包括数学运算、数据填充、结果输出和变量督学等操作，每个节点上的操作都需要分配到具体的物理设备（如CPU、GPU）上执行·。

基于梯度下降优化求解的机器学习问题，通常都可以分为前向图求值与后向图求梯度两个计算阶段。其中，前向图由用户编程代码完成, 主要过程包括定义模型的目标函数（Object function）和损失函数（loss function）,输入、输出数据的形状、类型等；后向图由Tensorflow的优化器自动生成，主要功能是计算模型参数的梯度值，并使用梯度值更新对应的模型参数。

**节点**

前向图中的节点统一称为操作，他们根据功能可以分为以下三类：

- 数学函数或表达式：例如Matmul、Softmax等

- 存储模型参数的变量：例如 Variable

- 占位符（placeholder）:例如 input和label

后向图的节点同样分为以下三类：

梯度值：根据前向图计算出的模型参数的梯度值

更新模型参数的操作： UpdateW、UpdateB

更行后的模型参数：SGD Trainer内的W和B

**有向边**

数据流图中的有向边用于定义操作之间的关系，他们分为两类：一类用来创数数据，绝大部门流动着张量的边都是此类，简称数据边。另一类是用来定义控制依赖（Control dependency）， 通过设定节点的牵制依赖决定相关节点的执行顺序。

**执行原理**

声明式编程的特点决定了在深度神经网络模型的数据流图上，各个节点的执行顺序并不完全依赖于代码中定义的顺序，而是与节点之间的逻辑关系以及运行时库的实现机制相关。

当用户使用Tensorflow执行指定数据流图时，其过程可以简述为以下四个步骤。

1. 以节点名称作为关键字、入度作为值，创建一张散列表，并将此数据流图上的所有节点放入散列表中

2. 以此数据流图创建一个可执行节点队列，并将散列表中入度为0的节点加入该队列，并从散列表中删除这些节点

3. 依次执行该队列的每一个节点，执行成功后将此节点输出指向的节点的入度值减1，更新散列表中对应节点的入度值。

4. 重复步骤2.和步骤3.，直到可执行节点队列变为空

**数据载体： 张量**

张量广泛应用于物理学、数学、工程学。在不同的应用领域，张量由不同的学术定义。这里引用维基百科中的定义：张量是用来表示一些矢量、标量和其它张量之间线性关系的多线性函数，这些线性关系的典型例子由内积、外积、线性映射以及笛卡尔积。

在Tensorflow中张量是数据流图上的数据载体。Tensorflow使用张量统一表示所有数据。

**模型载体：操作**

数据流图由节点和有向边组成，每个节点对应不同具体的操作。因此操作时模型实体功能的载体。数据流图中节点按照功能不同分为以下三种：

计算节点：对应的是无状态的计算或控制操作

存储节点：对应有状态的变量操作， 通常用来存储模型参数

数据节点：对应占位符操作 

**训练工具：优化器**

优化算法是指使用损失值不断优化模型参数， 以尽可能减小损失值得算法

Tensorflow提供得优化器：Adam、Rmsprop、Momentum等 

# 3. Tensorflow 数据处理方法

Tensorfow主要涉及三类数据，分别是输入数据集、模型参数、命令行参数。其中没输入数据集是用来训练、验证和测试的数据集合。模型参数主要指模型算法涉及到的权重值和偏置值。命令行参数则指启动tensorflow程序时输入的可选项，包括模型超参数和集群参数等。

传统的数据集处理流程：首先将输入数据集从文件系统读取到内存中，然后将其转换为模型需要的输入数据格式，接着传入数据流图，开始真正的模型训练过程。

大数据集处理，一般由大量数据文件组成，由于数据规模较大，无法一次性全部加载到内存中，用户只能在每一步训练时加载数据，这将阻塞模型的计算任务。Tensorflow提供了以输入流水线方式从多个文件中并行读取数据的方法，这使得模型训练所需的数据能够实时填充进数据流图。该方法的核心思想是实现多个数据缓冲区以确保任何时刻内存中都有数据可以填充进数据流图

多个csv文件读取示例：

```python
# 创建文件名队列
fn_queue = tf.train.string_input_producer(['txt1.csv', 'txt2.csv'])
# 创建csv文件读取器
reader = tf.TextLineReader()
# 从文件名队列中取出一条记录
_, value = reader.read(fn_queue)
# 设置数据默认值
record_defaults = [[0], [0], [0.0], [0.0]]
# 将数据记录的每个字段转换为特征张量
id, age, income, outgo = tf.decode_csv(value,
                                      record_defaults=record_defaults)
# 将所有特征张量组合在一起形成一条记录
features = tf.stack([id ,age, income, outgo])
```

**TFRecords文件**

Tensorflow指定标准文件格式，用于存储有结构的序列化字段

# 4. Tensorflow编程框架

**单机程序编程框架**

单机程序是指启动和运行都仅在一台机器的一个进程中完成的程序，这种程序的模型参数只在GPU/CPU的内存之间传输，没有网络通信的开销，非常适合参数不多、计算量小的模型，相比分布式程序，单机程序的设计更加简单，编程难度更低。

**分布式程序编程框架**

# 5. Tensorboard

Tensorboard是Tensorflow项目开发组的深度学习可视化工具，它以Web应用程序的形态可视化数据流图、学习过程和高纬度数据。

# 6. Tensorflow Serving

一套标准化的模型托管工具，能够打通从模型训练到发布的全流程，并以较低的管理成本和便捷的部署方式为用户提供在线推理服务

# 7. 算法模型

**卷积神经网络 - Convolutional Neural Network（CNN）**

**循环神经网络 - Recurrent Neural Network（RNN）**



​    