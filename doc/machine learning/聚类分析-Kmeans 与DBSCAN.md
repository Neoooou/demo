# 聚类分析-  K-means 与DBSCAN

**机器学习分类**：

![机器学习算法系列之二：算法概述| 断鸿声里，立尽斜阳](https://flat2010.github.io/2017/01/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%B3%BB%E5%88%97%E4%B9%8B%E4%BA%8C%EF%BC%9A%E7%AE%97%E6%B3%95%E6%A6%82%E8%BF%B0/%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E5%88%86%E7%B1%BB.PNG)

**聚类**：将相似的对象归到同一簇中，使得同一簇中的数据相似性尽可能大，同时不同簇中的数据的差异性也尽可能大。即同一类的数据尽可能聚到一起，不同类的数据尽量分离。

**常用聚类算法**：K-means、DBSCAN（基于密度的空间聚类方法, Density Based spatial clustering of application with noise）、层次聚类...

*K-Means 聚类*

1. 首先，选择一个K值，即簇数，随机初始化它们各自的中心点。

2. 通过计算数据点与簇心之间的距离来对每个点进行分类，数据点归类于与其最近的簇, 即
   $$
   Labeli = argmin(dist(Xi - \alpha j))
   $$
   Xi - 数据点， aj - 簇心

3. 更新簇心为每个簇所有数据点的均值。
   $$
   \alpha j = \frac{1}{N(\alpha j)} \sum_{i=1}Xi
   $$
   

4. 重复步骤2、3，直到达到一定的迭代轮次或者收敛到一定的误差之内。

优点：收敛快、可解释强

缺点：K值不好把握、对异常点敏感



*DBSCAN*：基于密度的空间聚类算法，将具有足够高密度的区域划分为一簇，它将簇定义为密度相连点的最大集合。

**参数**：

- 可达半径：领域密度阈值

- MinPts：领域样本个数阈值

**描述定义**

1） 𝜖ϵ-邻域：对于𝑥𝑗∈𝐷xj∈D，其𝜖ϵ-邻域包含样本集D中与𝑥𝑗xj的距离不大于𝜖ϵ的子样本集，即𝑁𝜖(𝑥𝑗)={𝑥𝑖∈𝐷|𝑑𝑖𝑠𝑡𝑎𝑛𝑐𝑒(𝑥𝑖,𝑥𝑗)≤𝜖}Nϵ(xj)={xi∈D|distance(xi,xj)≤ϵ}, 这个子样本集的个数记为|𝑁𝜖(𝑥𝑗)||Nϵ(xj)|　

　　　　2) 核心对象：对于任一样本𝑥𝑗∈𝐷xj∈D，如果其𝜖ϵ-邻域对应的𝑁𝜖(𝑥𝑗)Nϵ(xj)至少包含MinPts个样本，即如果|𝑁𝜖(𝑥𝑗)|≥𝑀𝑖𝑛𝑃𝑡𝑠|Nϵ(xj)|≥MinPts，则𝑥𝑗xj是核心对象。　

　　　　3）密度直达：如果𝑥𝑖xi位于𝑥𝑗xj的𝜖ϵ-邻域中，且𝑥𝑗xj是核心对象，则称𝑥𝑖xi由𝑥𝑗xj密度直达。注意反之不一定成立，即此时不能说𝑥𝑗xj由𝑥𝑖xi密度直达, 除非且𝑥𝑖xi也是核心对象。

　　　　4）密度可达：对于𝑥𝑖xi和𝑥𝑗xj,如果存在样本样本序列𝑝1,𝑝2,...,𝑝𝑇p1,p2,...,pT,满足𝑝1=𝑥𝑖,𝑝𝑇=𝑥𝑗p1=xi,pT=xj, 且𝑝𝑡+1pt+1由𝑝𝑡pt密度直达，则称𝑥𝑗xj由𝑥𝑖xi密度可达。也就是说，密度可达满足传递性。此时序列中的传递样本𝑝1,𝑝2,...,𝑝𝑇−1p1,p2,...,pT−1均为核心对象，因为只有核心对象才能使其他样本密度直达。注意密度可达也不满足对称性，这个可以由密度直达的不对称性得出。

　　　　5）密度相连：对于𝑥𝑖xi和𝑥𝑗xj,如果存在核心对象样本𝑥𝑘xk，使𝑥𝑖xi和𝑥𝑗xj均由𝑥𝑘xk密度可达，则称𝑥𝑖xi和𝑥𝑗xj密度相连。注意密度相连关系是满足对称性的。

**计算步骤**

输入：样本集D=(𝑥1,𝑥2,...,𝑥𝑚)(x1,x2,...,xm)，邻域参数(𝜖,𝑀𝑖𝑛𝑃𝑡𝑠)(ϵ,MinPts), 样本距离度量方式

输出： 簇划分C.　

　　　　1）初始化核心对象集合Ω=∅Ω=∅, 初始化聚类簇数k=0，初始化未访问样本集合ΓΓ = D,  簇划分C = ∅∅

　　　　2) 对于j=1,2,...m, 按下面的步骤找出所有的核心对象：

　　　　　　a) 通过距离度量方式，找到样本𝑥𝑗xj的𝜖ϵ-邻域子样本集𝑁𝜖(𝑥𝑗)Nϵ(xj)

　　　　　　b) 如果子样本集样本个数满足|𝑁𝜖(𝑥𝑗)|≥𝑀𝑖𝑛𝑃𝑡𝑠|Nϵ(xj)|≥MinPts， 将样本𝑥𝑗xj加入核心对象样本集合：Ω=Ω∪{𝑥𝑗}Ω=Ω∪{xj}

　　　　3）如果核心对象集合Ω=∅Ω=∅，则算法结束，否则转入步骤4.

　　　　4）在核心对象集合ΩΩ中，随机选择一个核心对象𝑜o，初始化当前簇核心对象队列Ω𝑐𝑢𝑟={𝑜}Ωcur={o}, 初始化类别序号k=k+1，初始化当前簇样本集合𝐶𝑘={𝑜}Ck={o}, 更新未访问样本集合Γ=Γ−{𝑜}Γ=Γ−{o}

　　　　5）如果当前簇核心对象队列Ω𝑐𝑢𝑟=∅Ωcur=∅，则当前聚类簇𝐶𝑘Ck生成完毕, 更新簇划分C={𝐶1,𝐶2,...,𝐶𝑘}{C1,C2,...,Ck}, 更新核心对象集合Ω=Ω−𝐶𝑘Ω=Ω−Ck， 转入步骤3。否则更新核心对象集合Ω=Ω−𝐶𝑘Ω=Ω−Ck。

　　　　6）在当前簇核心对象队列Ω𝑐𝑢𝑟Ωcur中取出一个核心对象𝑜′o′,通过邻域距离阈值𝜖ϵ找出所有的𝜖ϵ-邻域子样本集𝑁𝜖(𝑜′)Nϵ(o′)，令Δ=𝑁𝜖(𝑜′)∩ΓΔ=Nϵ(o′)∩Γ, 更新当前簇样本集合𝐶𝑘=𝐶𝑘∪ΔCk=Ck∪Δ, 更新未访问样本集合Γ=Γ−ΔΓ=Γ−Δ, 更新Ω𝑐𝑢𝑟=Ω𝑐𝑢𝑟∪(Δ∩Ω)−𝑜′Ωcur=Ωcur∪(Δ∩Ω)−o′，转入步骤5.

　　　　输出结果为： 簇划分C={𝐶1,𝐶2,...,𝐶𝑘}

优点：聚类结果没有偏倚，不受异常点影响，可以在聚类的同时发现异常点

缺点：如果样本集不均匀或者间距相差较大时，聚类质量较差



![image-20210202202136382](/Users/zhangran/Library/Application Support/typora-user-images/image-20210202202136382.png)

https://scikit-learn.org/stable/modules/clustering.html#clustering

聚类结果评估：

轮廓系数(Silhouette Score)，

1. 对于第 i 个对象，计算它到所属簇中所有其他对象的平均距离，记 ai （体现凝聚度）
2. 对于第 i 个对象和不包含该对象的任意簇，计算该对象到给定簇中所有对象的平均距离，记 bi （体现分离度）
3. 第 i 个对象的轮廓系数为 si = (bi-ai)/max(ai, bi)  

 

